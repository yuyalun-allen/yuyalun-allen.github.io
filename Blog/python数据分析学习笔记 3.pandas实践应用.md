# python数据分析入门——pandas实践应用
*本篇笔记是我在阅读《利用python进行数据分析》第6-12章后的凭借自己理解复述的内容，如有纰漏还恳请指正。由于本人水平所限，表述未必严谨，系统学习请参照《利用python进行数据分析》。*

## 数据分析流程
首先谈一谈我理解中的数据分析流程：

1. 数据读写：从结构化、半结构化的数据收集开始，我们可能从各种途径获取数据，得到各种数据源。比较常见的数据格式有txt、csv、xlsx、特殊分隔符分割文件、文本文件和数据库文件。因此，为了对数据进行分析，首先需要完成的就是数据读写。
2. 数据清洗：从现实生活中收集的数据，尤其是半结构化数据中存在大量不完整的或重复的数据，对于这些数据进行清洗是得到可靠结论的必要条件，所谓*garbage in, garbage out*。
3. 数据转换：数据转换操作需要将清洗后整洁的数据整理成后续模型需要的形式，并初步完成数据信息的描述性探索，对于数据反映的情况有大致了解。
4. 数据加载：遵循机器学习或统计分析的流程，将整理好的数据输入合适的模型，最终对得到的结果加以解读。

## 数据读写
pandas提供了一系列读文件和写文件操作函数：read_csv/read_table/read_clipboard ......
to_csv/to_table/to_xlsx ......除了通用格式外还需要根据数据处理的特殊情况，指定特定参数，完成数据的完整输入。

可以通过Python第三方库对于数据库管理系统的支持进行数据库的读写操作，如利用pymysql操作MySQL数据库。

## 数据清洗
数据清洗，首先是缺失值的处理。缺失值pandas默认将其设置为NaN（Not a Number），若原文件中有其他缺失值的表示方式（如NA，None）可以在函数中指定。补充缺失值函数fillna()，丢弃缺失值函数dropna().

数据清洗另一项工作就是处理重复行。重复行的检测可以利用duplicated函数，该函数返回一个bool型数组，可以进一步索引查看重复行的内容。重复行的处理是利用drop_duplicated函数，直接丢弃重复行，保证数据的唯一性（一般情况下对于重复数据的处理就是如此）。另外drop_duplicated函数也可以指定列进行去重。

## 数据转换
从这里开始，你就需要根据自己数据的实际情况以及模型的选择来具体分析了。
