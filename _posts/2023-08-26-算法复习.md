---
layout: post
catagories: 编程技术
---

> 准备保研/秋招的算法考核，把曾经学习过的算法知识点拿出来复习以下，特此鸣谢我的算法老师——沈老师，以下代码均参考了沈老师的示例代码，但是以我的思维方式和代码风格展现。

# 分治
核心是递归函数，通过递归的方式解决问题，通过每次让问题规模**成比例减小**让效率得到对数级提高。

> 换言之如果未能让问题规模比例缩小，就只是一般的递归解法而已，对于算法复杂度没有减小，甚至因为使用递归函数，可能影响性能。

我心目中最伟大的分治算法当属归并排序和快速排序

``` python
def merge_sort(list, left, right):
    if left == right:
        return

    mid = (right + left) // 2
    merge_sort(list, left, mid)
    merge_sort(list, mid + 1, right)
    merge(list, left, right)
```

``` python
def quick_sort(my_list, left, right):
    if left == right or left - 1 == right:
        return

    mid = partition(my_list, left, right)
    quick_sort(my_list, left, mid - 1)
    quick_sort(my_list, mid + 1, right)
```

# 贪心
我理解中有两种贪心算法，一种是优化问题中，更快地尽可能得到更好的解；另一种是精确算法中，从一个简单的初始解出发，通过不同的思考角度以及数据结构以更高的效率得到正确答案。当然此处的贪心指的是后者，那也没什么好说的，全依赖于你看问题的角度是否合适。

很多经典的伟大算法都是贪心的产物，如Dijkstra

``` python
# dijkstra with priority queue
# 使用邻接矩阵的方式表示graph
def dijkstra(start, graph):
    shortest_path = list()
    checked_vertices = set()
    critical_section_vertices = PriorityQueue()

    shortest_path[start] = 0
    checked_vertices.add(start)
    critical_section_vertices.add((start, 0))

    while _ in range(len(graph)): # 这里图的遍历确切的次数为顶点个数，若等待队列为空可能导致更长的路径被更新
        pivot = critical_section_vertices.remove()
        checked_vertices.add(pivot[0])
        for vertex in neighbor(graph, pivot[0]):
            if vertex not in checked_vertices:
                if shortest_path[vertex] < pivot[1] + graph[pivot[0]][vertex]:
                    critical_section_vertices.add((vertex, pivot[1] + graph[pivot[0]][vertex]))
    
    return shortest_path
```

Dijkstra算法求解最短路是bfs和贪心算法的巧妙结合，贪心策略体现在bfs搜索过程中的是，已访问的所有节点中的最短路将被放入`checked_vertices`，不再访问。因此此处的循环结束条件不应该是队列为空。

这里如果不使用优先队列就需要手动找出已访问的最短路径。


想要用贪心法解决问题完全取决于你的思路是否开阔（当然如果问题本身NP-hard，思路再开阔也无济于事，但也可以通过放松条件来得到某种条件下的最优解，如Dijkstra）

# 图遍历
直接上代码
``` python
# dfs
# Recursive function for dfs
def dfs(pivot, checked_vertices, graph):
    checked_vertices.add(pivot)
    for vertex in neighbor(graph, pivot):
        if vertex not in checked_vertices:
            dfs(vertex, checked_vertices, graph)
```

``` python
# bfs
# Queue implementation for bfs
def bfs(start, graph):
    checked_vertices = set()
    critical_section_vertices = queue()

    critical_section_vertices.add(start)
    checked_vertices.add(start)

    while not critical_section_vertices.empty():
        pivot = critical_section_vertices.remove()
        for vertex in neighbor(graph, pivot):
            if vertex not in checked_vertices:
                critical_section_vertices.add(vertex)
                checked_vertices.add(vertex)
```

可以看到作为遍历方式，bfs和dfs的基本框架非常相似。都是从pivot顶点开始，访问它的邻节点，标记出已访问的节点避免重复访问。

只有一个大的区别和一个小的微妙区别。大的区别正如它们名字中所提到的，一个使用递归方式（当然可以使用栈的数据结构）深度优先搜索，另一个使用队列数据结构广度优先搜索。

微妙的区别在于我在代码中并未出现已访问节点，而只有已检查节点，而且检查的位置似乎不同：在dfs中进入函数时将其标记为已检查，而bfs中入队时就将其标记为已检查，因为checked的作用就是避免重复检查，而不影响访问次序。

~~*没听明白就当我在胡扯就好了*~~

# DP
动态规划是改善的枚举，核心思想是后续的枚举`e.g. DP[i + k]`用到之前枚举`e.g. DP[i]`的结论，以大大改善枚举的效率。

经典的DP问题，Knapsack（背包）问题

``` python
# knapsack problem with dp array
def knapsack(capacity, weights, values):
    dp = [[0 for _ in range(len(weights))] for _ in range(capacity + 1)]
    # dp[i][j] 代表剩余容量为 i， 在挑选第 j 个item最大收益
    # 要求dp[capacity][len(weights) - 1]
    # if i > weight[j]:
    #   dp[i][j] = max(dp[i][j-1], dp[i - weight[j]][j - 1] + value[j])
    for i in range(capacity):
        dp[i][0] = 0 if weights[0] > i else values[0]
    for i in range(capacity):
        for j in range(1, len(weights)):
            if i > weight[j]:
                dp[i][j] = max(dp[i][j - 1], dp[i - weights[j]][j - 1] + values[j])
            else:
                dp[i][j] = dp[i][j - 1]
    return dp[capacity][len(weights) - 1]
```

``` python
# knapsack problem with recursion and cache
def knapsack(capacity, weights, values, step, dp):
    if step == len(weights):
        return 0
    if (step, capacity) in dp.keys():
        return dp[(step, capacity)]
    if capacity > weights[step]:
        value = max(knapsack(capacity, weights, values, step + 1, dp),
        knapsack(capacity - weights[step], weights, values, step + 1, dp) + values[step])
    else:
        value = knapsack(capacity, weights, values, step + 1, dp)
    dp[(step, capacity)] = value
    return value

knapsack(50, [20, 40, 20], [30, 40, 35], 0, {})
```

如果想要知道到底选了哪些items，可以使用以下代码追溯
``` python
capacity = 50
dp = {}
weights = [20, 40, 20]
values = [30, 40, 35]
trace = [False for _ in range(len(weights))]

for step in range(len(weights)):
    if step < len(weights) - 1 and dp[(step, capacity)] != dp[(step + 1, capacity)]:
        trace[step] = True
        capacity -= weights[step]
    elif step == len(weights) - 1 and dp[(step, capacity)] != 0:
        trace[step] = True
        capacity -= weights[step]

print(trace)
```

# 回溯/分支限界
回溯/分支限界是改善的枚举，其中回溯用到了图遍历（实际上是**树**遍历）的dfs算法，分支限界用到了图遍历（同样是**树**遍历）的bfs算法，二者通过限界函数改善枚举效率，为NP难问题提供一种相对可行的解法。

此处奉上沈老师的BT（back trace）框架 *（据说是老师原创）*。

``` python
class Backtracking():
    def __init__(self,n,problem_type,bound_func,feasible_func):
        self.n=n
        self.__problem_type=problem_type
        self.__exceedBound=bound_func
        self.__mark=feasible_func

    def __exceedBound(self,v):
        pass

    def __mark(self,v):
        pass

    def __advance(self,v):
        return

    # 核心就是这个dfs， v为最终结果
    def __dfs(self,v):
        # 访问节点，如果在访问节点的时候需要做什么就在该函数中定义
        self.__advance(v)
        if len(v)==self.n: # is leaf
            # 判断结果，这是树的遍历和图的遍历的区别，也是回溯发挥作用的部分
            self.__mark(v)
        else:
            # 一般的dfs，区别在于此处获得邻节点需要排除不可能的情况，如重复排列
            adjs=self.__adjList(v)
            for e in adjs:
                # 剪枝
                if not self.__exceedBound(v+[e]):
                    v.append(e)
                    self.__dfs(v)
        # 回溯核心，如果回到树的根节点就返回，否则回退一个结果
        # 细究回退的情况有两种，一种是检查完叶子节点，另一种是检查完非叶子节点后的所有子节点
        self.__backtrack(v)
    
    def __backtrack(self,v):
        if len(v)==0:
            print('the end...')
        else:
            del v[-1]

    def __adjList(self,v):
        y=[] 
        if self.__problem_type==1: #Subset Problem
            y+=[0]+[1] 
        else: #Permutation Problem
            for i in range(1,self.n+1):
                if not i in v:
                    y+=[i]
        return y

    def run(self,starting_state=[]):
        self.__dfs(starting_state)
```

最后斗胆尝试一下老师未给出示例代码的旅行商问题的分支限界解法，其中找lower bound和搜索顺序都和沈老师讲的不大相同，主要参考[这篇文章](https://segmentfault.com/a/1190000022670389)。lower bound的估计会影响剪枝效率，这篇文章中提到的方法不如老师上课讲的精确，但是简单可行，此处给出代码实现参考(未验证其正确性，欢迎讨论)

```python
from queue import PriorityQueue

def tsp_branch_and_bound(graph, start):
    lower_bounds = [min(row) for row in graph]
    critical_section_vertices = PriorityQueue()

    critical_section_vertices.put((sum(lower_bounds), [start]))

    while not critical_section_vertices.empty():
        pivot = critical_section_vertices.get()
        if len(pivot[1]) == len(graph) + 1:
            print(pivot[1])
            return pivot[0]
        if len(pivot[1]) == len(graph):
            lb = graph[pivot[1][-1]][start] + pivot[0]- lower_bounds[pivot[1][-1]]
            visited = pivot[1].copy()
            visited.append(start)
            critical_section_vertices.put((lb, visited))
        for vertex in [vertex for vertex in range(len(graph)) if vertex not in pivot[1]]:
            lb = pivot[0] - lower_bounds[pivot[1][-1]] + graph[pivot[1][-1]][vertex]
            visited = pivot[1].copy()
            visited.append(vertex)
            critical_section_vertices.put((lb, visited))

```
